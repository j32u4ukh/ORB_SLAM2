# 編譯期
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j4

# 執行期
$ /home/j32u4ukh/Documents/ORB_SLAM2> 


./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI00-02.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/00"
./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI00-02.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/01"
./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI00-02.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/02"

./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI03.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/03"

./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI04-12.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/04"
.
.
.
./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI04-12.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/12"


$ /home/j32u4ukh/Documents/ORB_SLAM2/build> 

../Examples/Monocular/mono_kitti ../Vocabulary/ORBvoc.txt ../Examples/Monocular/KITTI00-02.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/00"

# 執行時間
[foreach 改版前]
詞袋數據讀取 00:09.80
median tracking time: 0.0596703
mean tracking time: 0.0700843
建圖 10:53.73

[foreach 改版後]
median tracking time: 0.0712685
mean tracking time: 0.0836848
建圖 10:16.31

[函式封裝]
New Map created with 508 points
median tracking time: 0.0859725
mean tracking time: 0.0943997
#KeyFrame: 642
#MapPoint: 76626

Vocabulary loaded! Cost 9.44923 s.
#KeyFrame: 772
#MapPoint: 93859

// ==================================================
// TODO: Total time 有誤，秒數出現負值
// ==================================================
Total time: 8:-31043.6
Median tracking time: 0.0663731
Mean tracking time: 0.0722137




virtual int g2o::SparseOptimizer::optimize(int, bool): 0 vertices to optimize, maybe forgot to call initializeOptimization()
沒有頂點的可能原因：
* 都被標注為 isBad 導致沒有被加入
* 數據沒有被確實加到陣列中



DBoW2::FeatureVector kf_feature_vector = vFeatVecKF;
DBoW2::FeatureVector f_feature_vector = F.mFeatVec;

if(kf_feature_vector.first < )

for (auto feature_vector : boost::combine(kf_feature_vector, f_feature_vector)) {

    // FeatureVector == std::map<NodeId, std::vector<unsigned int> >
    pair<DBoW2::NodeId, std::vector<unsigned int>> kf_feature;
    pair<DBoW2::NodeId, std::vector<unsigned int>> f_feature;

    boost::tie(kf_feature, f_feature) = feature_vector;
    DBoW2::NodeId kf_node_id = kf_feature.first;
    DBoW2::NodeId f_node_id = f_feature.first;

    // kf_feature 起始節點較 f_feature 小
    if(kf_node_id < f_node_id){

        // 將 kf_feature 起始節點設為第 f_node_id 個節點
        kf_feature = vFeatVecKF.lower_bound(f_node_id);
    }
    
    // kf_feature 起始節點較 f_feature 大
    else if(kf_node_id > f_node_id){

        // 將 f_feature 起始節點設為第 kf_node_id 個節點
        f_feature = F.mFeatVec.lower_bound(kf_node_id);
    }   
}

[Optimizer]
g2o::SparseOptimizer optimizer;
g2o::BlockSolver_6_3::LinearSolverType *linearSolver = new g2o::LinearSolverEigen<g2o::BlockSolver_6_3::PoseMatrixType>();
g2o::BlockSolver_6_3 *solver_ptr = new g2o::BlockSolver_6_3(linearSolver);
g2o::OptimizationAlgorithmLevenberg *solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
optimizer.setAlgorithm(solver);


g2o::SparseOptimizer optimizer;
optimizer.setVerbose(false);
g2o::BlockSolver_7_3::LinearSolverType *linearSolver = new g2o::LinearSolverEigen<g2o::BlockSolver_7_3::PoseMatrixType>();
g2o::BlockSolver_7_3 *solver_ptr = new g2o::BlockSolver_7_3(linearSolver);
g2o::OptimizationAlgorithmLevenberg *solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
solver->setUserLambdaInit(1e-16);
optimizer.setAlgorithm(solver);


g2o::SparseOptimizer optimizer;
g2o::BlockSolverX::LinearSolverType *linearSolver = new g2o::LinearSolverDense<g2o::BlockSolverX::PoseMatrixType>();
g2o::BlockSolverX *solver_ptr = new g2o::BlockSolverX(linearSolver);
g2o::OptimizationAlgorithmLevenberg *solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
optimizer.setAlgorithm(solver);


[Vertex]
g2o::EdgeSim3ProjectXYZ *e12 = new g2o::EdgeSim3ProjectXYZ();
e12->setVertex(0, dynamic_cast<g2o::OptimizableGraph::Vertex *>(optimizer.vertex(id2)));
e12->setVertex(1, dynamic_cast<g2o::OptimizableGraph::Vertex *>(optimizer.vertex(0)));
e12->setMeasurement(obs1);





[Fuse]






[SearchBySim3]

// Transform from KF1 to KF2 and search
// 『關鍵幀 pKF1』投影到『關鍵幀 pKF2』上尋找匹配點
for (int i1 = 0; i1 < N1; i1++)
{
    // 『地圖點 pMP』：『關鍵幀 pKF1』的第 i1 個地圖點
    MapPoint *pMP = vpMapPoints1[i1];

    if (!pMP || vbAlreadyMatched1[i1]){
        continue;
    }

    if (pMP->isBad()){
        continue;
    }

    cv::Mat p3Dw = pMP->GetWorldPos();
    cv::Mat p3Dc1 = R1w * p3Dw + t1w;

    // 利用『相似轉換矩陣』將『關鍵幀 pKF1』上的特徵點轉換到『關鍵幀 pKF2』的座標系下
    cv::Mat p3Dc2 = sR21 * p3Dc1 + t21;

    // Depth must be positive
    if (p3Dc2.at<float>(2) < 0.0){
        continue;
    }

    const float invz = 1.0 / p3Dc2.at<float>(2);
    const float x = p3Dc2.at<float>(0) * invz;
    const float y = p3Dc2.at<float>(1) * invz;

    // 像素座標
    const float u = fx * x + cx;
    const float v = fy * y + cy;

    // Point must be inside the image
    // 傳入座標點是否在關鍵幀的成像範圍內
    if (!pKF2->IsInImage(u, v)){
        continue;
    }

    // 考慮金字塔層級的『地圖點 pMP』最大可能深度
    const float maxDistance = pMP->GetMaxDistanceInvariance();

    // 考慮金字塔層級的『地圖點 pMP』最小可能深度
    const float minDistance = pMP->GetMinDistanceInvariance();

    // 『關鍵幀 pKF2』相機中心到空間點的距離，即『關鍵幀 pKF2』座標系下的深度
    const float dist3D = cv::norm(p3Dc2);

    // Depth must be inside the scale invariance region
    if (dist3D < minDistance || dist3D > maxDistance){
        continue;
    }

    // Compute predicted octave
    const int nPredictedLevel = pMP->PredictScale(dist3D, pKF2);

    // Search in a radius
    const float radius = th * pKF2->mvScaleFactors[nPredictedLevel];

    // 返回以 (u, v) 為圓心，在搜索半徑內，在指定金字塔層級找到的關鍵點的索引值
    const vector<size_t> vIndices = pKF2->GetFeaturesInArea(u, v, radius);

    if (vIndices.empty()){
        continue;
    }

    // Match to the most similar keypoint in the radius
    // 『地圖點 pMP』（『關鍵幀 pKF1』的第 i1 個地圖點）的描述子
    const cv::Mat dMP = pMP->GetDescriptor();

    int bestDist = INT_MAX;
    int bestIdx = -1;

    // 遍歷『關鍵幀 pKF2』當中可能和『地圖點 pMP』（『關鍵幀 pKF1』的第 i1 個地圖點）匹配的特徵點
    for(const size_t idx : vIndices){

        const cv::KeyPoint &kp = pKF2->mvKeysUn[idx];

        if (kp.octave < nPredictedLevel - 1 || kp.octave > nPredictedLevel){
            continue;
        }

        // 『關鍵幀 pKF2』的第 idx 個特徵點的描述子
        const cv::Mat &dKF = pKF2->mDescriptors.row(idx);

        // 『關鍵幀 pKF2』的第 idx 個特徵點的描述子 和 『地圖點 pMP』的描述子 之間的距離
        const int dist = DescriptorDistance(dMP, dKF);

        // 篩選描述子距離最短的情況
        if (dist < bestDist)
        {
            bestDist = dist;

            // 『關鍵幀 pKF2』的第 bestIdx 個特徵點和『地圖點 pMP』最相似
            bestIdx = idx;
        }
    }

    // 若描述子距離足夠近
    if (bestDist <= TH_HIGH)
    {
        // vnMatch1 匹配關係：『關鍵幀 pKF1』的第 i1 個地圖點＆『關鍵幀 pKF2』的第 bestIdx 個特徵點
        vnMatch1[i1] = bestIdx;
    }
}

// Transform from KF2 to KF1 and search
for (int i2 = 0; i2 < N2; i2++)
{
    // 『地圖點 pMP』：『關鍵幀 pKF2』的第 i2 個地圖點
    MapPoint *pMP = vpMapPoints2[i2];

    if (!pMP || vbAlreadyMatched2[i2]){
        continue;
    }

    if (pMP->isBad()){
        continue;
    }

    cv::Mat p3Dw = pMP->GetWorldPos();
    cv::Mat p3Dc2 = R2w * p3Dw + t2w;

    // 利用『相似轉換矩陣』將『關鍵幀 pKF2』上的特徵點轉換到『關鍵幀 pKF1』的座標系下
    cv::Mat p3Dc1 = sR12 * p3Dc2 + t12;

    // Depth must be positive
    if (p3Dc1.at<float>(2) < 0.0){
        continue;
    }

    const float invz = 1.0 / p3Dc1.at<float>(2);
    const float x = p3Dc1.at<float>(0) * invz;
    const float y = p3Dc1.at<float>(1) * invz;

    const float u = fx * x + cx;
    const float v = fy * y + cy;

    // Point must be inside the image
    if (!pKF1->IsInImage(u, v)){
        continue;
    }

    // 考慮金字塔層級的『地圖點 pMP』最大可能深度
    const float maxDistance = pMP->GetMaxDistanceInvariance();

    // 考慮金字塔層級的『地圖點 pMP』最小可能深度
    const float minDistance = pMP->GetMinDistanceInvariance();

    // 『關鍵幀 pKF1』相機中心到空間點的距離，即『關鍵幀 pKF1』座標系下的深度
    const float dist3D = cv::norm(p3Dc1);

    // Depth must be inside the scale pyramid of the image
    if (dist3D < minDistance || dist3D > maxDistance){
        continue;
    }

    // Compute predicted octave
    const int nPredictedLevel = pMP->PredictScale(dist3D, pKF1);

    // Search in a radius of 2.5*sigma(ScaleLevel)
    const float radius = th * pKF1->mvScaleFactors[nPredictedLevel];

    // 返回以 (u, v) 為圓心，在搜索半徑內，在指定金字塔層級找到的關鍵點的索引值
    const vector<size_t> vIndices = pKF1->GetFeaturesInArea(u, v, radius);

    if (vIndices.empty()){
        continue;
    }

    // Match to the most similar keypoint in the radius
    // 『地圖點 pMP』（『關鍵幀 pKF2』的第 i2 個地圖點）的描述子
    const cv::Mat dMP = pMP->GetDescriptor();

    int bestDist = INT_MAX;
    int bestIdx = -1;

    // 遍歷『關鍵幀 pKF1』當中可能和『地圖點 pMP』（『關鍵幀 pKF2』的第 i2 個地圖點）匹配的特徵點
    for(const size_t idx : vIndices){

        const cv::KeyPoint &kp = pKF1->mvKeysUn[idx];

        if (kp.octave < nPredictedLevel - 1 || kp.octave > nPredictedLevel){
            continue;
        }

        // 『關鍵幀 pKF1』的第 idx 個特徵點的描述子
        const cv::Mat &dKF = pKF1->mDescriptors.row(idx);

        // 『關鍵幀 pKF1』的第 idx 個特徵點的描述子 和 『地圖點 pMP』的描述子 之間的距離
        const int dist = DescriptorDistance(dMP, dKF);

        // 篩選描述子距離最短的情況
        if (dist < bestDist)
        {
            bestDist = dist;

            // 『關鍵幀 pKF1』的第 bestIdx 個特徵點和『地圖點 pMP』最相似
            bestIdx = idx;
        }
    }

    // 若描述子距離足夠近
    if (bestDist <= TH_HIGH)
    {
        // vnMatch2 匹配關係：『關鍵幀 pKF2』的第 i2 個地圖點＆『關鍵幀 pKF1』的第 bestIdx 個特徵點
        vnMatch2[i2] = bestIdx;
    }
}




[SearchByProjection]

// For each Candidate MapPoint Project and Match
for(MapPoint *pMP : vpPoints){

    // Discard Bad MapPoints and already found
    // spAlreadyFound.count(pMP)：排除已存在的地圖點
    if (pMP->isBad() || spAlreadyFound.count(pMP)){
        continue;
    }

    // Get 3D Coords.
    cv::Mat p3Dw = pMP->GetWorldPos();

    // Transform into Camera Coords.
    cv::Mat p3Dc = Rcw * p3Dw + tcw;

    // Depth must be positive
    if (p3Dc.at<float>(2) < 0.0){
        continue;
    }

    // Project into Image
    const float invz = 1 / p3Dc.at<float>(2);
    const float x = p3Dc.at<float>(0) * invz;
    const float y = p3Dc.at<float>(1) * invz;

    const float u = fx * x + cx;
    const float v = fy * y + cy;

    // Point must be inside the image
    if (!pKF->IsInImage(u, v)){
        continue;
    }

    // Depth must be inside the scale invariance region of the point
    const float maxDistance = pMP->GetMaxDistanceInvariance();
    const float minDistance = pMP->GetMinDistanceInvariance();

    // 相機中心指向空間點
    cv::Mat PO = p3Dw - Ow;

    // 深度
    const float dist = cv::norm(PO);

    if (dist < minDistance || dist > maxDistance){
        continue;
    }

    // Viewing angle must be less than 60 deg
    // 取得『地圖點 pMP』的法向量
    cv::Mat Pn = pMP->GetNormal();

    if (PO.dot(Pn) < 0.5 * dist){
        continue;
    }

    // 『關鍵幀 pKF』根據當前『地圖點 pMP』的深度，估計場景規模
    int nPredictedLevel = pMP->PredictScale(dist, pKF);

    // Search in a radius
    const float radius = th * pKF->mvScaleFactors[nPredictedLevel];

    // 取得區域內的候選關鍵點的索引值
    const vector<size_t> vIndices = pKF->GetFeaturesInArea(u, v, radius);

    if (vIndices.empty()){
        continue;
    }

    // Match to the most similar keypoint in the radius
    // 取得『地圖點 pMP』描述子
    const cv::Mat dMP = pMP->GetDescriptor();

    int bestDist = 256;
    int bestIdx = -1;

    for(const size_t idx : vIndices){

        if (vpMatched[idx]){
            continue;
        }

        // 『關鍵點 kp』的金字塔層級
        const int &kpLevel = pKF->mvKeysUn[idx].octave;

        // kpLevel 可以是：(nPredictedLevel - 1) 或 nPredictedLevel
        if (kpLevel < nPredictedLevel - 1 || kpLevel > nPredictedLevel){
            continue;
        }

        // 取得『關鍵幀 pKF』的第 idx 個特徵點的描述子
        const cv::Mat &dKF = pKF->mDescriptors.row(idx);

        // 計算『地圖點 pMP』描述子和『關鍵幀 pKF』的第 idx 個特徵點的描述子之間的距離
        const int dist = DescriptorDistance(dMP, dKF);

        // 篩選距離最近的『距離 bestDist』和『關鍵幀索引值 bestIdx』
        if (dist < bestDist)
        {
            bestDist = dist;
            bestIdx = idx;
        }
    }

    if (bestDist <= TH_LOW)
    {
        // 『關鍵幀 pKF』的第 idx 個特徵點對應『地圖點 pMP』
        vpMatched[bestIdx] = pMP;
        nmatches++;
    }
}


// 遍歷『關鍵幀 pKF』的已配對地圖點
for (size_t i = 0, iend = vpMPs.size(); i < iend; i++)
{
    MapPoint *pMP = vpMPs[i];

    if (pMP)
    {
        if (!pMP->isBad() && !sAlreadyFound.count(pMP))
        {
            //Project
            cv::Mat x3Dw = pMP->GetWorldPos();
            cv::Mat x3Dc = Rcw * x3Dw + tcw;

            const float xc = x3Dc.at<float>(0);
            const float yc = x3Dc.at<float>(1);
            const float invzc = 1.0 / x3Dc.at<float>(2);

            const float u = CurrentFrame.fx * xc * invzc + CurrentFrame.cx;
            const float v = CurrentFrame.fy * yc * invzc + CurrentFrame.cy;

            if (u < CurrentFrame.mnMinX || u > CurrentFrame.mnMaxX){
                continue;
            }

            if (v < CurrentFrame.mnMinY || v > CurrentFrame.mnMaxY){
                continue;
            }

            // Compute predicted scale level
            cv::Mat PO = x3Dw - Ow;
            float dist3D = cv::norm(PO);

            const float maxDistance = pMP->GetMaxDistanceInvariance();
            const float minDistance = pMP->GetMinDistanceInvariance();

            // Depth must be inside the scale pyramid of the image
            if (dist3D < minDistance || dist3D > maxDistance){
                continue;
            }

            // 根據當前距離與最遠可能距離，換算出當前尺度
            int nPredictedLevel = pMP->PredictScale(dist3D, &CurrentFrame);

            // Search in a window
            const float radius = th * CurrentFrame.mvScaleFactors[nPredictedLevel];

            // 返回以 (u, v) 為圓心，在搜索半徑內，在指定金字塔層級找到的關鍵點的索引值
            const vector<size_t> vIndices2 = 
                            CurrentFrame.GetFeaturesInArea(u, v, radius, nPredictedLevel - 1, 
                                                        nPredictedLevel + 1);

            if (vIndices2.empty()){
                continue;
            }

            // 取得『關鍵幀 pKF』的已配對地圖點的描述子
            const cv::Mat dMP = pMP->GetDescriptor();

            int bestDist = 256;
            int bestIdx2 = -1;

            // 遍歷關鍵點的索引值
            for(const size_t i2 : vIndices2){

                if (CurrentFrame.mvpMapPoints[i2]){
                    continue;
                }

                // 取得當前幀的第 i2 個特徵點的描述子
                const cv::Mat &d = CurrentFrame.mDescriptors.row(i2);

                // 計算描述子之間的距離（相似程度）
                const int dist = DescriptorDistance(dMP, d);

                if (dist < bestDist)
                {
                    bestDist = dist;
                    bestIdx2 = i2;
                }
            }

            if (bestDist <= ORBdist)
            {
                CurrentFrame.mvpMapPoints[bestIdx2] = pMP;
                nmatches++;

                if (mbCheckOrientation)
                {
                    float rot = pKF->mvKeysUn[i].angle - CurrentFrame.mvKeysUn[bestIdx2].angle;

                    if (rot < 0.0){
                        rot += 360.0f;
                    }

                    int bin = round(rot * factor);

                    if (bin == HISTO_LENGTH){
                        bin = 0;                            
                    }

                    assert(bin >= 0 && bin < HISTO_LENGTH);
                    rotHist[bin].push_back(bestIdx2);
                }
            }
        }
    }
}









