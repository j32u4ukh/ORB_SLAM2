# 編譯期
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j4

# 執行期
$ /home/j32u4ukh/Documents/ORB_SLAM2> 


./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI00-02.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/00"
./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI00-02.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/01"
./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI00-02.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/02"

./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI03.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/03"

./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI04-12.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/04"
.
.
.
./Examples/Monocular/mono_kitti Vocabulary/ORBvoc.txt Examples/Monocular/KITTI04-12.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/12"


$ /home/j32u4ukh/Documents/ORB_SLAM2/build> 

../Examples/Monocular/mono_kitti ../Vocabulary/ORBvoc.txt ../Examples/Monocular/KITTI00-02.yaml "/media/j32u4ukh/TOSHIBA EXT/SLAM/data_odometry_gray/dataset/sequences/00"

# 執行時間
[foreach 改版前]
詞袋數據讀取 00:09.80
median tracking time: 0.0596703
mean tracking time: 0.0700843
建圖 10:53.73

[foreach 改版後]
median tracking time: 0.0712685
mean tracking time: 0.0836848
建圖 10:16.31

[函式封裝]
New Map created with 508 points
median tracking time: 0.0859725
mean tracking time: 0.0943997
#KeyFrame: 642
#MapPoint: 76626

Vocabulary loaded! Cost 9.44923 s.
#KeyFrame: 724
#MapPoint: 87397
Total time: 10:23.4392
Median tracking time: 0.0776799
Mean tracking time: 0.0859752



virtual int g2o::SparseOptimizer::optimize(int, bool): 0 vertices to optimize, maybe forgot to call initializeOptimization()
沒有頂點的可能原因：
* 都被標注為 isBad 導致沒有被加入
* 數據沒有被確實加到陣列中



DBoW2::FeatureVector kf_feature_vector = vFeatVecKF;
DBoW2::FeatureVector f_feature_vector = F.mFeatVec;

if(kf_feature_vector.first < )

for (auto feature_vector : boost::combine(kf_feature_vector, f_feature_vector)) {

    // FeatureVector == std::map<NodeId, std::vector<unsigned int> >
    pair<DBoW2::NodeId, std::vector<unsigned int>> kf_feature;
    pair<DBoW2::NodeId, std::vector<unsigned int>> f_feature;

    boost::tie(kf_feature, f_feature) = feature_vector;
    DBoW2::NodeId kf_node_id = kf_feature.first;
    DBoW2::NodeId f_node_id = f_feature.first;

    // kf_feature 起始節點較 f_feature 小
    if(kf_node_id < f_node_id){

        // 將 kf_feature 起始節點設為第 f_node_id 個節點
        kf_feature = vFeatVecKF.lower_bound(f_node_id);
    }
    
    // kf_feature 起始節點較 f_feature 大
    else if(kf_node_id > f_node_id){

        // 將 f_feature 起始節點設為第 kf_node_id 個節點
        f_feature = F.mFeatVec.lower_bound(kf_node_id);
    }   
}

[Optimizer]
g2o::SparseOptimizer optimizer;
g2o::BlockSolver_6_3::LinearSolverType *linearSolver = new g2o::LinearSolverEigen<g2o::BlockSolver_6_3::PoseMatrixType>();
g2o::BlockSolver_6_3 *solver_ptr = new g2o::BlockSolver_6_3(linearSolver);
g2o::OptimizationAlgorithmLevenberg *solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
optimizer.setAlgorithm(solver);


g2o::SparseOptimizer optimizer;
optimizer.setVerbose(false);
g2o::BlockSolver_7_3::LinearSolverType *linearSolver = new g2o::LinearSolverEigen<g2o::BlockSolver_7_3::PoseMatrixType>();
g2o::BlockSolver_7_3 *solver_ptr = new g2o::BlockSolver_7_3(linearSolver);
g2o::OptimizationAlgorithmLevenberg *solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
solver->setUserLambdaInit(1e-16);
optimizer.setAlgorithm(solver);


g2o::SparseOptimizer optimizer;
g2o::BlockSolverX::LinearSolverType *linearSolver = new g2o::LinearSolverDense<g2o::BlockSolverX::PoseMatrixType>();
g2o::BlockSolverX *solver_ptr = new g2o::BlockSolverX(linearSolver);
g2o::OptimizationAlgorithmLevenberg *solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);
optimizer.setAlgorithm(solver);


[Vertex]
g2o::EdgeSim3ProjectXYZ *e12 = new g2o::EdgeSim3ProjectXYZ();
e12->setVertex(0, dynamic_cast<g2o::OptimizableGraph::Vertex *>(optimizer.vertex(id2)));
e12->setVertex(1, dynamic_cast<g2o::OptimizableGraph::Vertex *>(optimizer.vertex(0)));
e12->setMeasurement(obs1);



==========================================================================================================================================================

上層 selectFuseTarget 將根據『一般單目/立體視覺/單目 Sim3』化分成多個階段
1. 獨立到函式之外

// 『地圖點 pMP』的世界座標
cv::Mat p3Dw = pMP->GetWorldPos();

// 『地圖點 pMP』由世紀座標系 轉換到 相機座標系
cv::Mat p3Dc = Rcw * p3Dw + t1w;

cv::Mat sp3Dc = sim3 * p3Dc + t21;


2. 取得像素座標 getPixelCoordinates / getPixelCoordinatesStereo /

// Depth must be positive
if (sp3Dc.at<float>(2) < 0.0f)
{
    return std::tuple<bool, int, int>{true, -1, -1};
}

const float invz = 1 / sp3Dc.at<float>(2);

// 重投影之歸一化平面座標
const float x = sp3Dc.at<float>(0) * invz;
const float y = sp3Dc.at<float>(1) * invz;

// 重投影之像素座標
const float u = fx * x + cx;
const float v = fy * y + cy;

// ＝＝＝＝＝ For stero ＝＝＝＝＝
const float ur = u - bf * invz;
// ＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝

// Point must be inside the image
// 傳入座標點是否超出關鍵幀的成像範圍
if (!pKF->IsInImage(u, v))
{
    return std::tuple<bool, int, int>{true, -1, -1};
}


3. 評估地圖點的深度估計，是否在有效的區間內 isValidDistance / isValidDistanceSim3

// 考慮金字塔層級的『地圖點 pMP』最大可能深度
const float maxDistance = pMP->GetMaxDistanceInvariance();

// 考慮金字塔層級的『地圖點 pMP』最小可能深度
const float minDistance = pMP->GetMinDistanceInvariance();

float dist3D;

if(consider_included_angle)
{
    // 『相機中心 Ow』指向『地圖點 pMP』之向量
    cv::Mat PO = p3Dw - Ow;

    // 『地圖點 pMP』深度（『相機中心 Ow』到『地圖點 pMP』之距離）
    dist3D = cv::norm(PO);

    // Depth must be inside the scale pyramid of the image
    // 『相機中心 Ow』到『地圖點 pMP』之距離應在可能深度的區間內
    if (dist3D < minDistance || dist3D > maxDistance)
    {
        return std::tuple<bool, int, int>{true, -1, -1};
    }
    
    // Viewing angle must be less than 60 deg
    // 地圖點之法向量
    // SerachBySim3 沒有這段
    cv::Mat Pn = pMP->GetNormal();

    // SerachBySim3 沒有這段
    // 計算 PO 和 Pn 的夾角是否超過 60 度（餘弦值超過 0.5）
    if (PO.dot(Pn) < 0.5 * dist3D)
    {
        return std::tuple<bool, int, int>{true, -1, -1};
    }
}
else
{
    // 『地圖點 pMP』深度（『相機中心 Ow』到『地圖點 pMP』之距離）
    dist3D = cv::norm(sp3Dc);

    // Depth must be inside the scale pyramid of the image
    // 『相機中心 Ow』到『地圖點 pMP』之距離應在可能深度的區間內
    if (dist3D < minDistance || dist3D > maxDistance)
    {
        return std::tuple<bool, int, int>{true, -1, -1};
    }
}   


4. 共同參數準備

// 『關鍵幀 pKF』根據當前『地圖點 pMP』的深度，估計場景規模
int nPredictedLevel = pMP->PredictScale(dist3D, pKF);

// Search in a radius
const float radius = th * pKF->mvScaleFactors[nPredictedLevel];

// 指定區域內的候選關鍵點的索引值
const vector<size_t> vIndices = pKF->GetFeaturesInArea(u, v, radius);

if (vIndices.empty()){
continue;
}

// Match to the most similar keypoint in the radius
// 取得『地圖點 pMP』描述子
const cv::Mat dMP = pMP->GetDescriptor();

bestDist = INT_MAX;
bestIdx = -1;

5. for(const size_t idx : vIndices) 當中

continue_kp_level = checkFuseTarget(pKF, idx, nPredictedLevel);

///// 不同需求客製化 /////

updateFuseTarget(pKF, idx, dMP, bestDist, bestIdx);


}


==========================================================================================================================================================





[SearchByProjection]

// For each Candidate MapPoint Project and Match
for(MapPoint *pMP : vpPoints){

    // Discard Bad MapPoints and already found
    // spAlreadyFound.count(pMP)：排除已存在的地圖點
    if (pMP->isBad() || spAlreadyFound.count(pMP)){
        continue;
    }

    // Get 3D Coords.
    cv::Mat p3Dw = pMP->GetWorldPos();

    // Transform into Camera Coords.
    cv::Mat p3Dc = Rcw * p3Dw + tcw;

    // Depth must be positive
    if (p3Dc.at<float>(2) < 0.0){
        continue;
    }

    // Project into Image
    const float invz = 1 / p3Dc.at<float>(2);
    const float x = p3Dc.at<float>(0) * invz;
    const float y = p3Dc.at<float>(1) * invz;

    const float u = fx * x + cx;
    const float v = fy * y + cy;

    // Point must be inside the image
    if (!pKF->IsInImage(u, v)){
        continue;
    }

    // Depth must be inside the scale invariance region of the point
    const float maxDistance = pMP->GetMaxDistanceInvariance();
    const float minDistance = pMP->GetMinDistanceInvariance();

    // 相機中心指向空間點
    cv::Mat PO = p3Dw - Ow;

    // 深度
    const float dist = cv::norm(PO);

    if (dist < minDistance || dist > maxDistance){
        continue;
    }

    // Viewing angle must be less than 60 deg
    // 取得『地圖點 pMP』的法向量
    cv::Mat Pn = pMP->GetNormal();

    if (PO.dot(Pn) < 0.5 * dist){
        continue;
    }

    // 『關鍵幀 pKF』根據當前『地圖點 pMP』的深度，估計場景規模
    int nPredictedLevel = pMP->PredictScale(dist, pKF);

    // Search in a radius
    const float radius = th * pKF->mvScaleFactors[nPredictedLevel];

    // 取得區域內的候選關鍵點的索引值
    const vector<size_t> vIndices = pKF->GetFeaturesInArea(u, v, radius);

    if (vIndices.empty()){
        continue;
    }

    // Match to the most similar keypoint in the radius
    // 取得『地圖點 pMP』描述子
    const cv::Mat dMP = pMP->GetDescriptor();

    int bestDist = 256;
    int bestIdx = -1;

    for(const size_t idx : vIndices){

        if (vpMatched[idx]){
            continue;
        }

        // 『關鍵點 kp』的金字塔層級
        const int &kpLevel = pKF->mvKeysUn[idx].octave;

        // kpLevel 可以是：(nPredictedLevel - 1) 或 nPredictedLevel
        if (kpLevel < nPredictedLevel - 1 || kpLevel > nPredictedLevel){
            continue;
        }

        // 取得『關鍵幀 pKF』的第 idx 個特徵點的描述子
        const cv::Mat &dKF = pKF->mDescriptors.row(idx);

        // 計算『地圖點 pMP』描述子和『關鍵幀 pKF』的第 idx 個特徵點的描述子之間的距離
        const int dist = DescriptorDistance(dMP, dKF);

        // 篩選距離最近的『距離 bestDist』和『關鍵幀索引值 bestIdx』
        if (dist < bestDist)
        {
            bestDist = dist;
            bestIdx = idx;
        }
    }

    if (bestDist <= TH_LOW)
    {
        // 『關鍵幀 pKF』的第 idx 個特徵點對應『地圖點 pMP』
        vpMatched[bestIdx] = pMP;
        nmatches++;
    }
}


// 遍歷『關鍵幀 pKF』的已配對地圖點
for (size_t i = 0, iend = vpMPs.size(); i < iend; i++)
{
    MapPoint *pMP = vpMPs[i];

    if (pMP)
    {
        if (!pMP->isBad() && !sAlreadyFound.count(pMP))
        {
            //Project
            cv::Mat x3Dw = pMP->GetWorldPos();
            cv::Mat x3Dc = Rcw * x3Dw + tcw;

            const float xc = x3Dc.at<float>(0);
            const float yc = x3Dc.at<float>(1);
            const float invzc = 1.0 / x3Dc.at<float>(2);

            const float u = CurrentFrame.fx * xc * invzc + CurrentFrame.cx;
            const float v = CurrentFrame.fy * yc * invzc + CurrentFrame.cy;

            if (u < CurrentFrame.mnMinX || u > CurrentFrame.mnMaxX){
                continue;
            }

            if (v < CurrentFrame.mnMinY || v > CurrentFrame.mnMaxY){
                continue;
            }

            // Compute predicted scale level
            cv::Mat PO = x3Dw - Ow;
            float dist3D = cv::norm(PO);

            const float maxDistance = pMP->GetMaxDistanceInvariance();
            const float minDistance = pMP->GetMinDistanceInvariance();

            // Depth must be inside the scale pyramid of the image
            if (dist3D < minDistance || dist3D > maxDistance){
                continue;
            }

            // 根據當前距離與最遠可能距離，換算出當前尺度
            int nPredictedLevel = pMP->PredictScale(dist3D, &CurrentFrame);

            // Search in a window
            const float radius = th * CurrentFrame.mvScaleFactors[nPredictedLevel];

            // 返回以 (u, v) 為圓心，在搜索半徑內，在指定金字塔層級找到的關鍵點的索引值
            const vector<size_t> vIndices2 = 
                            CurrentFrame.GetFeaturesInArea(u, v, radius, nPredictedLevel - 1, 
                                                        nPredictedLevel + 1);

            if (vIndices2.empty()){
                continue;
            }

            // 取得『關鍵幀 pKF』的已配對地圖點的描述子
            const cv::Mat dMP = pMP->GetDescriptor();

            int bestDist = 256;
            int bestIdx2 = -1;

            // 遍歷關鍵點的索引值
            for(const size_t i2 : vIndices2){

                if (CurrentFrame.mvpMapPoints[i2]){
                    continue;
                }

                // 取得當前幀的第 i2 個特徵點的描述子
                const cv::Mat &d = CurrentFrame.mDescriptors.row(i2);

                // 計算描述子之間的距離（相似程度）
                const int dist = DescriptorDistance(dMP, d);

                if (dist < bestDist)
                {
                    bestDist = dist;
                    bestIdx2 = i2;
                }
            }

            if (bestDist <= ORBdist)
            {
                CurrentFrame.mvpMapPoints[bestIdx2] = pMP;
                nmatches++;

                if (mbCheckOrientation)
                {
                    float rot = pKF->mvKeysUn[i].angle - CurrentFrame.mvKeysUn[bestIdx2].angle;

                    if (rot < 0.0){
                        rot += 360.0f;
                    }

                    int bin = round(rot * factor);

                    if (bin == HISTO_LENGTH){
                        bin = 0;                            
                    }

                    assert(bin >= 0 && bin < HISTO_LENGTH);
                    rotHist[bin].push_back(bestIdx2);
                }
            }
        }
    }
}




[SearchByBoW]

// 『關鍵幀 pKF1』和『關鍵幀 pKF2』上的關鍵點距離足夠小的關鍵點個數
    int ORBmatcher::SearchByBoW(KeyFrame *pKF1, KeyFrame *pKF2, vector<MapPoint *> &vpMatches12)
    {
        // 取得『關鍵幀 pKF1』的已校正關鍵點
        const vector<cv::KeyPoint> &vKeysUn1 = pKF1->mvKeysUn;

        // 取得『關鍵幀 pKF1』的特徵向量
        const DBoW2::FeatureVector &vFeatVec1 = pKF1->mFeatVec;

        // 取得『關鍵幀 pKF1』的地圖點
        const vector<MapPoint *> vpMapPoints1 = pKF1->GetMapPointMatches();

        // 取得『關鍵幀 pKF1』的描述子
        const cv::Mat &Descriptors1 = pKF1->mDescriptors;

        const vector<cv::KeyPoint> &vKeysUn2 = pKF2->mvKeysUn;
        const DBoW2::FeatureVector &vFeatVec2 = pKF2->mFeatVec;
        const vector<MapPoint *> vpMapPoints2 = pKF2->GetMapPointMatches();
        const cv::Mat &Descriptors2 = pKF2->mDescriptors;

        vpMatches12 = vector<MapPoint *>(vpMapPoints1.size(), static_cast<MapPoint *>(NULL));
        vector<bool> vbMatched2(vpMapPoints2.size(), false);

        vector<int> rotHist[HISTO_LENGTH];

        for (int i = 0; i < HISTO_LENGTH; i++){
            rotHist[i].reserve(500);
        }

        const float factor = 1.0f / HISTO_LENGTH;

        int nmatches = 0;

        // FeatureVector == std::map<NodeId, std::vector<unsigned int> >
        // 以一張圖片的每個特徵點在詞典某一層節點下爲條件進行分組，用來加速圖形特徵匹配——
        // 兩兩圖像特徵匹配只需要對相同 NodeId 下的特徵點進行匹配就好。
        // std::vector<unsigned int>：觀察到該特徵的 地圖點/關鍵點 的索引值
        DBoW2::FeatureVector::const_iterator f1it = vFeatVec1.begin();
        DBoW2::FeatureVector::const_iterator f1end = vFeatVec1.end();
        
        DBoW2::FeatureVector::const_iterator f2it = vFeatVec2.begin();
        DBoW2::FeatureVector::const_iterator f2end = vFeatVec2.end();

        while (f1it != f1end && f2it != f2end)
        {
            if (f1it->first == f2it->first)
            {
                vector<unsigned int> mp_indexs1 = f1it->second;
                vector<unsigned int> mp_indexs2 = f2it->second;

                for(const size_t idx1 : mp_indexs1)
                {
                    MapPoint *pMP1 = vpMapPoints1[idx1];

                    if (!pMP1){
                        continue;
                    }

                    if (pMP1->isBad()){
                        continue;
                    }

                    const cv::Mat &d1 = Descriptors1.row(idx1);

                    int bestDist1 = 256;
                    int bestIdx2 = -1;
                    int bestDist2 = 256;

                    for(const size_t idx2 : mp_indexs2)
                    {
                        MapPoint *pMP2 = vpMapPoints2[idx2];

                        if (vbMatched2[idx2] || !pMP2){
                            continue;
                        }

                        if (pMP2->isBad()){
                            continue;
                        }

                        const cv::Mat &d2 = Descriptors2.row(idx2);

                        // 『關鍵幀 pKF1』和『關鍵幀 pKF2』的關鍵點觀察到相似的特徵，計算兩關鍵點之間的距離
                        // 計算描述子之間的距離（相似程度）
                        int dist = DescriptorDistance(d1, d2);

                        if (dist < bestDist1)
                        {
                            bestDist2 = bestDist1;
                            bestDist1 = dist;
                            bestIdx2 = idx2;
                        }
                        else if (dist < bestDist2)
                        {
                            bestDist2 = dist;
                        }
                    }

                    // 若『關鍵幀 pKF1』和『關鍵幀 pKF2』上的關鍵點距離足夠小
                    if (bestDist1 < TH_LOW)
                    {
                        // 最小距離比第二小的距離要小的多
                        if (static_cast<float>(bestDist1) < mfNNratio * static_cast<float>(bestDist2))
                        {
                            // 『關鍵幀 pKF1』的第 idx1 個關鍵點，對應著『關鍵幀 pKF2』的第 bestIdx2 個地圖點
                            vpMatches12[idx1] = vpMapPoints2[bestIdx2];
                            vbMatched2[bestIdx2] = true;
                            nmatches++;

                            if (mbCheckOrientation)
                            {
                                updateRotHist(vKeysUn1[idx1], vKeysUn2[bestIdx2], 
                                              factor, idx1, rotHist);

                                // float rot = vKeysUn1[idx1].angle - vKeysUn2[bestIdx2].angle;

                                // if (rot < 0.0){
                                //     rot += 360.0f;
                                // }

                                // int bin = round(rot * factor);

                                // if (bin == HISTO_LENGTH){
                                //     bin = 0;
                                // }
                                
                                // assert(bin >= 0 && bin < HISTO_LENGTH);
                                // rotHist[bin].push_back(idx1);
                            }                            
                        }
                    }
                }

                f1it++;
                f2it++;
            }

            // NodeId 相同才進行比較，這裡將兩者的指標指向相同的 NodeId
            else if (f1it->first < f2it->first)
            {
                f1it = vFeatVec1.lower_bound(f2it->first);
            }
            else
            {
                f2it = vFeatVec2.lower_bound(f1it->first);
            }
        }

        if (mbCheckOrientation)
        {
            nmatches = convergenceMatched(nmatches, rotHist, 
                                          vpMatches12, static_cast<MapPoint *>(NULL));
        }

        return nmatches;
    }

    // 利用詞袋模型，快速匹配兩幀同時觀察到的地圖點 vpMapPointMatches
    int ORBmatcher::SearchByBoW(KeyFrame *pKF, Frame &F, vector<MapPoint *> &vpMapPointMatches)
    {
        // 從『參考關鍵幀 pKF』取出已匹配成功的地圖點
        const vector<MapPoint *> vpMapPointsKF = pKF->GetMapPointMatches();

        // 初始化匹配地圖點，長度初始化為『當前幀 F』的地圖點個數
        vpMapPointMatches = vector<MapPoint *>(F.N, static_cast<MapPoint *>(NULL));

        // 取得『參考關鍵幀 pKF』的特徵向量
        const DBoW2::FeatureVector &vFeatVecKF = pKF->mFeatVec;

        int nmatches = 0;

        // rotHist[i], rotHist[j] 都是 vector<int>
        vector<int> rotHist[HISTO_LENGTH];

        for (int i = 0; i < HISTO_LENGTH; i++){
            rotHist[i].reserve(500);
        }

        const float factor = 1.0f / HISTO_LENGTH;

        // We perform the matching over ORB that belong to the same vocabulary node (at a certain level)
        DBoW2::FeatureVector::const_iterator KFit = vFeatVecKF.begin();
        DBoW2::FeatureVector::const_iterator KFend = vFeatVecKF.end();

        DBoW2::FeatureVector::const_iterator Fit = F.mFeatVec.begin();
        DBoW2::FeatureVector::const_iterator Fend = F.mFeatVec.end();

        // FeatureVector == std::map<NodeId, std::vector<unsigned int> >
        while (KFit != KFend && Fit != Fend)
        {
            // first: NodeId
            // 相近的特徵點利用節點區分在一起，以加速運算，因此兩幀之間要比較時，只要比較節點(NodeId)相同的即可
            if (KFit->first == Fit->first)
            {
                // 特徵索引值列表 second: std::vector<unsigned int>
                // 包含了所有屬於『參考關鍵幀 pKF』詞袋模型的 KFit->first 節點的地圖點的索引值
                const vector<unsigned int> vIndicesKF = KFit->second;

                // 包含了所有屬於『當前幀 F』詞袋模型的 Fit->first 節點的地圖點的索引值
                const vector<unsigned int> vIndicesF = Fit->second;

                for(const unsigned int realIdxKF : vIndicesKF){

                    // 『參考關鍵幀 pKF』的第 realIdxKF 個地圖點在詞袋模型中，屬於 KFit->first 節點
                    MapPoint *pMP = vpMapPointsKF[realIdxKF];

                    if (!pMP){
                        continue;
                    }

                    if (pMP->isBad()){
                        continue;
                    }

                    // 同樣利用 realIdxKF 取得相對應的特徵點的描述子
                    const cv::Mat &dKF = pKF->mDescriptors.row(realIdxKF);

                    int bestDist1 = 256;
                    int bestIdxF = -1;
                    int bestDist2 = 256;

                    // 遍歷所有屬於『當前幀 F』詞袋模型的 Fit->first 節點的地圖點的索引值
                    for(const unsigned int realIdxF : vIndicesF){

                        if (vpMapPointMatches[realIdxF]){
                            continue;
                        }

                        const cv::Mat &dF = F.mDescriptors.row(realIdxF);

                        // 計算兩特徵點之間的距離
                        const int dist = DescriptorDistance(dKF, dF);

                        // 篩選兩特徵點之間的最短距離（bestDist1），以及其特徵點索引值（bestIdxF）
                        if (dist < bestDist1)
                        {
                            bestDist2 = bestDist1;
                            bestDist1 = dist;
                            bestIdxF = realIdxF;
                        }
                        else if (dist < bestDist2)
                        {
                            bestDist2 = dist;
                        }
                    }

                    // 若兩特徵點之間的距離足夠小
                    if (bestDist1 <= TH_LOW)
                    {
                        // 且比第二近的距離小的多
                        if (static_cast<float>(bestDist1) < mfNNratio * static_cast<float>(bestDist2))
                        {
                            // 第 bestIdxF 個匹配地圖點設為『參考關鍵幀 pKF』的第 realIdxKF 個地圖點 pMP
                            vpMapPointMatches[bestIdxF] = pMP;

                            // 取得第 realIdxKF 個地圖點相對應的（已校正）關鍵點
                            const cv::KeyPoint &kp = pKF->mvKeysUn[realIdxKF];

                            // 成功配對數
                            nmatches++;

                            if (mbCheckOrientation)
                            {
                                updateRotHist(kp, F.mvKeys[bestIdxF], factor, bestIdxF, rotHist);

                                // // 計算兩特徵點的角度差
                                // float rot = kp.angle - F.mvKeys[bestIdxF].angle;

                                // if (rot < 0.0){
                                //     rot += 360.0f;
                                // }

                                // // 將角度差換算成直方圖的索引值
                                // int bin = round(rot * factor);

                                // if (bin == HISTO_LENGTH){
                                //     bin = 0;
                                // }

                                // assert(bin >= 0 && bin < HISTO_LENGTH);
                                // rotHist[bin].push_back(bestIdxF);
                            }                            
                        }
                    }
                }

                // 更新 const_iterator
                KFit++;
                Fit++;
            }

            // KFit 起始節點較 Fit 小
            else if (KFit->first < Fit->first)
            {
                // 將 KFit 起始節點設為 Fit->first
                KFit = vFeatVecKF.lower_bound(Fit->first);
            }

            // KFit 起始節點較 Fit 大
            else
            {
                // 將 Fit 起始節點設為 KFit->first
                Fit = F.mFeatVec.lower_bound(KFit->first);
            }
        }

        if (mbCheckOrientation)
        {
            nmatches = convergenceMatched(nmatches, rotHist, 
                                          vpMapPointMatches, static_cast<MapPoint *>(NULL));
        }

        return nmatches;
    }

    

[SearchBySim3]

// Transform from KF1 to KF2 and search
// 『關鍵幀 pKF1』投影到『關鍵幀 pKF2』上尋找匹配點
for (int i1 = 0; i1 < N1; i1++)
{
    // 『地圖點 pMP』：『關鍵幀 pKF1』的第 i1 個地圖點
    MapPoint *pMP = vpMapPoints1[i1];

    if (!pMP || vbAlreadyMatched1[i1]){
        continue;
    }

    if (pMP->isBad()){
        continue;
    }

    cv::Mat p3Dw = pMP->GetWorldPos();
    cv::Mat p3Dc1 = R1w * p3Dw + t1w;

    // 利用『相似轉換矩陣』將『關鍵幀 pKF1』上的特徵點轉換到『關鍵幀 pKF2』的座標系下
    cv::Mat p3Dc2 = sR21 * p3Dc1 + t21;

    // Depth must be positive
    if (p3Dc2.at<float>(2) < 0.0){
        continue;
    }

    const float invz = 1.0 / p3Dc2.at<float>(2);
    const float x = p3Dc2.at<float>(0) * invz;
    const float y = p3Dc2.at<float>(1) * invz;

    // 像素座標
    const float u = fx * x + cx;
    const float v = fy * y + cy;

    // Point must be inside the image
    // 傳入座標點是否在關鍵幀的成像範圍內
    if (!pKF2->IsInImage(u, v)){
        continue;
    }

    // 考慮金字塔層級的『地圖點 pMP』最大可能深度
    const float maxDistance = pMP->GetMaxDistanceInvariance();

    // 考慮金字塔層級的『地圖點 pMP』最小可能深度
    const float minDistance = pMP->GetMinDistanceInvariance();

    // 『關鍵幀 pKF2』相機中心到空間點的距離，即『關鍵幀 pKF2』座標系下的深度
    const float dist3D = cv::norm(p3Dc2);

    // Depth must be inside the scale invariance region
    if (dist3D < minDistance || dist3D > maxDistance){
        continue;
    }

    // Compute predicted octave
    const int nPredictedLevel = pMP->PredictScale(dist3D, pKF2);

    // Search in a radius
    const float radius = th * pKF2->mvScaleFactors[nPredictedLevel];

    // 返回以 (u, v) 為圓心，在搜索半徑內，在指定金字塔層級找到的關鍵點的索引值
    const vector<size_t> vIndices = pKF2->GetFeaturesInArea(u, v, radius);

    if (vIndices.empty()){
        continue;
    }

    // Match to the most similar keypoint in the radius
    // 『地圖點 pMP』（『關鍵幀 pKF1』的第 i1 個地圖點）的描述子
    const cv::Mat dMP = pMP->GetDescriptor();

    int bestDist = INT_MAX;
    int bestIdx = -1;

    // 遍歷『關鍵幀 pKF2』當中可能和『地圖點 pMP』（『關鍵幀 pKF1』的第 i1 個地圖點）匹配的特徵點
    for(const size_t idx : vIndices){

        const cv::KeyPoint &kp = pKF2->mvKeysUn[idx];

        if (kp.octave < nPredictedLevel - 1 || kp.octave > nPredictedLevel){
            continue;
        }

        // 『關鍵幀 pKF2』的第 idx 個特徵點的描述子
        const cv::Mat &dKF = pKF2->mDescriptors.row(idx);

        // 『關鍵幀 pKF2』的第 idx 個特徵點的描述子 和 『地圖點 pMP』的描述子 之間的距離
        const int dist = DescriptorDistance(dMP, dKF);

        // 篩選描述子距離最短的情況
        if (dist < bestDist)
        {
            bestDist = dist;

            // 『關鍵幀 pKF2』的第 bestIdx 個特徵點和『地圖點 pMP』最相似
            bestIdx = idx;
        }
    }

    // 若描述子距離足夠近
    if (bestDist <= TH_HIGH)
    {
        // vnMatch1 匹配關係：『關鍵幀 pKF1』的第 i1 個地圖點＆『關鍵幀 pKF2』的第 bestIdx 個特徵點
        vnMatch1[i1] = bestIdx;
    }
}

// Transform from KF2 to KF1 and search
for (int i2 = 0; i2 < N2; i2++)
{
    // 『地圖點 pMP』：『關鍵幀 pKF2』的第 i2 個地圖點
    MapPoint *pMP = vpMapPoints2[i2];

    if (!pMP || vbAlreadyMatched2[i2]){
        continue;
    }

    if (pMP->isBad()){
        continue;
    }

    cv::Mat p3Dw = pMP->GetWorldPos();
    cv::Mat p3Dc2 = R2w * p3Dw + t2w;

    // 利用『相似轉換矩陣』將『關鍵幀 pKF2』上的特徵點轉換到『關鍵幀 pKF1』的座標系下
    cv::Mat p3Dc1 = sR12 * p3Dc2 + t12;

    // Depth must be positive
    if (p3Dc1.at<float>(2) < 0.0){
        continue;
    }

    const float invz = 1.0 / p3Dc1.at<float>(2);
    const float x = p3Dc1.at<float>(0) * invz;
    const float y = p3Dc1.at<float>(1) * invz;

    const float u = fx * x + cx;
    const float v = fy * y + cy;

    // Point must be inside the image
    if (!pKF1->IsInImage(u, v)){
        continue;
    }

    // 考慮金字塔層級的『地圖點 pMP』最大可能深度
    const float maxDistance = pMP->GetMaxDistanceInvariance();

    // 考慮金字塔層級的『地圖點 pMP』最小可能深度
    const float minDistance = pMP->GetMinDistanceInvariance();

    // 『關鍵幀 pKF1』相機中心到空間點的距離，即『關鍵幀 pKF1』座標系下的深度
    const float dist3D = cv::norm(p3Dc1);

    // Depth must be inside the scale pyramid of the image
    if (dist3D < minDistance || dist3D > maxDistance){
        continue;
    }

    // Compute predicted octave
    const int nPredictedLevel = pMP->PredictScale(dist3D, pKF1);

    // Search in a radius of 2.5*sigma(ScaleLevel)
    const float radius = th * pKF1->mvScaleFactors[nPredictedLevel];

    // 返回以 (u, v) 為圓心，在搜索半徑內，在指定金字塔層級找到的關鍵點的索引值
    const vector<size_t> vIndices = pKF1->GetFeaturesInArea(u, v, radius);

    if (vIndices.empty()){
        continue;
    }

    // Match to the most similar keypoint in the radius
    // 『地圖點 pMP』（『關鍵幀 pKF2』的第 i2 個地圖點）的描述子
    const cv::Mat dMP = pMP->GetDescriptor();

    int bestDist = INT_MAX;
    int bestIdx = -1;

    // 遍歷『關鍵幀 pKF1』當中可能和『地圖點 pMP』（『關鍵幀 pKF2』的第 i2 個地圖點）匹配的特徵點
    for(const size_t idx : vIndices){

        const cv::KeyPoint &kp = pKF1->mvKeysUn[idx];

        if (kp.octave < nPredictedLevel - 1 || kp.octave > nPredictedLevel){
            continue;
        }

        // 『關鍵幀 pKF1』的第 idx 個特徵點的描述子
        const cv::Mat &dKF = pKF1->mDescriptors.row(idx);

        // 『關鍵幀 pKF1』的第 idx 個特徵點的描述子 和 『地圖點 pMP』的描述子 之間的距離
        const int dist = DescriptorDistance(dMP, dKF);

        // 篩選描述子距離最短的情況
        if (dist < bestDist)
        {
            bestDist = dist;

            // 『關鍵幀 pKF1』的第 bestIdx 個特徵點和『地圖點 pMP』最相似
            bestIdx = idx;
        }
    }

    // 若描述子距離足夠近
    if (bestDist <= TH_HIGH)
    {
        // vnMatch2 匹配關係：『關鍵幀 pKF2』的第 i2 個地圖點＆『關鍵幀 pKF1』的第 bestIdx 個特徵點
        vnMatch2[i2] = bestIdx;
    }
}




